{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA RTX A5000\n",
      "tensor([[0.6411, 0.3169, 0.9890],\n",
      "        [0.3489, 0.2425, 0.1572],\n",
      "        [0.1931, 0.4706, 0.4741]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "flag = torch.cuda.is_available()\n",
    "print(flag)\n",
    "\n",
    "if flag:\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(torch.rand(3,3).cuda()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 确定项目根目录（假设当前工作目录是项目的根目录）\n",
    "project_root = os.path.abspath(\"..\")\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "import pickle\n",
    "from ai import ai_battle, MinimaxAI, MCTSAI\n",
    "from game.chess_game import ChessGame\n",
    "from CelestialVault.instances import ExampleThreadManager\n",
    "\n",
    "\n",
    "class TrainDataThread(ExampleThreadManager):\n",
    "    def get_args(self, obj: object):\n",
    "        return (mcts_ai_0, mcts_ai_0, ChessGame((5, 5), 2), False)\n",
    "    \n",
    "    def process_result(self):\n",
    "        all_training_data = []\n",
    "        result_dict = self.get_result_dict()\n",
    "        for d in result_dict:\n",
    "            over_game = result_dict[d]\n",
    "            history_board = over_game.history_board\n",
    "            history_move = over_game.history_move\n",
    "            for step in history_board:\n",
    "                if step+1 not in history_board.keys():\n",
    "                    continue\n",
    "                board = self.process_board(history_board, step)\n",
    "                # if (board, history_move[step+1]) in all_training_data: # 这样效果并不好\n",
    "                #     continue\n",
    "                all_training_data.append((board, history_move[step+1]))\n",
    "        return all_training_data\n",
    "    \n",
    "    def process_board(self, history_board, step):\n",
    "        color = 1 if step % 2 == 0 else -1\n",
    "        \n",
    "        processed_board = []\n",
    "        for row in history_board[step]:\n",
    "            processed_row = []\n",
    "            for cell in row:\n",
    "                processed_cell = cell + [color]\n",
    "                if processed_cell[0] == float(\"inf\"):\n",
    "                    processed_cell[0] = 5\n",
    "                processed_row.append(processed_cell)\n",
    "            processed_board.append(processed_row)\n",
    "        return processed_board\n",
    "\n",
    "\n",
    "\n",
    "minimax_ai = MinimaxAI(5)\n",
    "mcts_ai_0 = MCTSAI(1000, flag=True)\n",
    "mcts_ai_1 = MCTSAI(1000, flag=False)\n",
    "\n",
    "train_data_threader = TrainDataThread(\n",
    "            ai_battle,\n",
    "            thread_num=50,\n",
    "            tqdm_desc='trainDataProcess',\n",
    "            show_progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "trainDataProcess:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "trainDataProcess: 100%|██████████| 50/50 [36:57<00:00, 44.34s/it]\n",
      "trainDataProcess: 100%|██████████| 50/50 [30:56<00:00, 37.12s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1542"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from time import strftime, localtime\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def save_data(data):\n",
    "    data_size = len(data)\n",
    "    now_time = strftime(\"%m-%d-%H\", localtime())\n",
    "    pickle.dump(data, open(f\"train_data/all_training_data({now_time})({data_size}).pkl\", \"wb\"))\n",
    "\n",
    "def train_data(train_num):\n",
    "    train_data_threader.start(range(train_num), \"serial\")\n",
    "    train_data_threader.handle_error()\n",
    "    all_training_data = train_data_threader.process_result()\n",
    "\n",
    "    save_data(all_training_data)\n",
    "    \n",
    "    return all_training_data\n",
    "\n",
    "all_training_data = []\n",
    "for _ in range(1):\n",
    "    all_training_data += train_data(100)\n",
    "\n",
    "len(all_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(all_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_data = load_data(r\"G:\\Project\\Celestial-Chess\\ai\\train_data\\all_training_data(06-13-23)(1506).pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9598"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_data = all_training_data[:]\n",
    "all_training_data = []\n",
    "\n",
    "for i in old_data:\n",
    "    if i in all_training_data:\n",
    "        continue\n",
    "    all_training_data.append(i)\n",
    "\n",
    "len(all_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1542"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        board_state, move = self.data[idx]\n",
    "        board_state = torch.tensor(board_state, dtype=torch.float32)\n",
    "        move = move[0] * 5 + move[1]\n",
    "        return board_state, move\n",
    "\n",
    "dataset = ChessDataset(all_training_data)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from time import strftime, localtime\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from ai.deeplearning import ChessModel, DeepLearningAI\n",
    "\n",
    "# 设置CuDNN选项\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "model = ChessModel().cuda() # 初始化模型，并将其移动到GPU上\n",
    "criterion = nn.CrossEntropyLoss() # 定义交叉熵损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # 定义Adam优化器\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 10  # 训练10个epoch\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        # 调整输入的维度，并将其移动到GPU上\n",
    "        # inputs 的原始形状是 (batch_size, height, width, channels)，也就是 (32, 5, 5, 3)\n",
    "        # inputs.permute(0, 3, 1, 2) 会将 inputs 的维度从 (32, 5, 5, 3) 转换为 (32, 3, 5, 5)\n",
    "        inputs = inputs.permute(0, 3, 1, 2).cuda()  # (batch_size, channels, height, width)\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        # 清零梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累积损失\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # 每100个batch打印一次loss\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "data_size = len(dataset)\n",
    "now_time = strftime(\"%m-%d-%H\", localtime())\n",
    "torch.save(model.state_dict(), f'models/chess_ai_model({now_time})({data_size}).pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 确定项目根目录（假设当前工作目录是项目的根目录）\n",
    "project_root = os.path.abspath(\"..\")\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from ai import ai_battle, MinimaxAI, MCTSAI\n",
    "from ai.deeplearning import DeepLearningAI\n",
    "from game.chess_game import ChessGame\n",
    "\n",
    "def get_model_score_by_mcts(test_model):\n",
    "    score_dict = dict()\n",
    "    for i in tqdm(range(10, 1000, 10)):\n",
    "        win = 0\n",
    "        test_mcts = MCTSAI(i, flag=True)\n",
    "        for _ in range(100):\n",
    "            game = ai_battle(test_model, test_mcts, ChessGame((5, 5), 2), display=False)\n",
    "            if game.who_is_winner() == 1:\n",
    "                win += 1\n",
    "\n",
    "        score_dict[i] = win / 100\n",
    "        if score_dict[i] < 0.5:\n",
    "            return i - 10, score_dict\n",
    "        \n",
    "\n",
    "# 深度学习AI\n",
    "deep_learning_dict = {\n",
    "                      # {10: 0.7, 20: 0.68, 30: 0.47}\n",
    "                      \"models/chess_ai_model(06-13-19).pth\": 20, # 未知\n",
    "                      # {10: 0.7, 20: 0.51, 30: 0.43}\n",
    "                      \"models/chess_ai_model(06-15-17)(1506).pth\": 20, # MCTSAI(1000, flag=True) 训练100轮\n",
    "                      # {10: 0.75, 20: 0.65, 30: 0.47}\n",
    "                      'models/chess_ai_model(06-15-17)(1471).pth': 20, # MCTSAI(10000, flag=True) 训练100轮\n",
    "                      # {10: 0.63, 20: 0.41}\n",
    "                      'models/chess_ai_model(06-15-17)(936).pth': 10, # MCTSAI(10000, flag=True) 训练100轮并去重\n",
    "                      # {10: 0.82, 20: 0.76, 30: 0.65, 40: 0.57, 50: 0.56, 60: 0.44}\n",
    "                      'models/chess_ai_model(06-15-17)(15475).pth': 50, # MCTSAI(1000, flag=True) 训练1000轮\n",
    "                      # {10: 0.84, 20: 0.58, 30: 0.57, 40: 0.61, 50: 0.56, 60: 0.41}\n",
    "                      'models/chess_ai_model(06-15-17)(9598).pth': 50, # MCTSAI(1000, flag=True) 训练1000轮并去重\n",
    "                      # {10: 0.32}\n",
    "                      \"models/chess_ai_model(06-16-15)(1400).pth\": 0, # MCTSAI(10000, flag=False) 训练100轮(没标错, 真是0分)\n",
    "                      # {10: 0.55, 20: 0.48}\n",
    "                      'models/chess_ai_model(06-16-20)(1542).pth': 10, # MCTSAI(1000, flag=False) 训练100轮\n",
    "                      }\n",
    "\n",
    "                    \n",
    "# deep_learning_ai_0 = DeepLearningAI(\"models/chess_ai_model(06-15-17)(936).pth\") \n",
    "\n",
    "# 测试AI\n",
    "test_minimax = MinimaxAI(6) # score: 50\n",
    "test_mcts_0 = MCTSAI(1000, flag=True)\n",
    "test_mcts_1 = MCTSAI(100, flag=True) # score: 50\n",
    "test_mcts_2 = MCTSAI(100, flag=False) # score: 80\n",
    "test_mcts_3 = MCTSAI(60, flag=True) # 50, {10: 0.82, 20: 0.76, 30: 0.53, 40: 0.57, 50: 0.51, 60: 0.32}\n",
    "test_mcts_4 = MCTSAI(60, flag=False) # 110, {10: 0.86, 20: 0.86, 30: 0.77, 40: 0.63, 50: 0.58, 60: 0.63, 70: 0.58, 80: 0.52, 90: 0.51, 100: 0.5, 110: 0.52, 120: 0.45}\n",
    "test_mcts_5 = MCTSAI(10, flag=True) # 0, {10: 0.45}\n",
    "test_mcts_6 = MCTSAI(10, flag=False) # 50, {10: 0.76, 20: 0.69, 30: 0.57, 40: 0.56, 50: 0.5, 60: 0.4}\n",
    "test_mcts_7 = MCTSAI(500, flag=True)\n",
    "\n",
    "# 与其他AI算法进行对战\n",
    "# ai_battle(deep_learning_ai_2, test_mcts_0, ChessGame((5, 5), 2), display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/99 [1:44:18<22:50:51, 894.04s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_model_score_by_mcts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_mcts_7\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 19\u001b[0m, in \u001b[0;36mget_model_score_by_mcts\u001b[1;34m(test_model)\u001b[0m\n\u001b[0;32m     17\u001b[0m test_mcts \u001b[38;5;241m=\u001b[39m MCTSAI(i, flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m---> 19\u001b[0m     game \u001b[38;5;241m=\u001b[39m \u001b[43mai_battle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_mcts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChessGame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m game\u001b[38;5;241m.\u001b[39mwho_is_winner() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     21\u001b[0m         win \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mg:\\Project\\Celestial-Chess\\ai\\test_ai.py:19\u001b[0m, in \u001b[0;36mai_battle\u001b[1;34m(ai_blue, ai_red, test_game, display)\u001b[0m\n\u001b[0;32m     17\u001b[0m color \u001b[38;5;241m=\u001b[39m test_game\u001b[38;5;241m.\u001b[39mget_color()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m color \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 19\u001b[0m     move \u001b[38;5;241m=\u001b[39m \u001b[43mai_blue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_best_move\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_game\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m     move \u001b[38;5;241m=\u001b[39m ai_red\u001b[38;5;241m.\u001b[39mfind_best_move(test_game)\n",
      "File \u001b[1;32mg:\\Project\\Celestial-Chess\\ai\\mcts.py:110\u001b[0m, in \u001b[0;36mMCTSAI.find_best_move\u001b[1;34m(self, game)\u001b[0m\n\u001b[0;32m    108\u001b[0m target_color \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mget_color()\n\u001b[0;32m    109\u001b[0m root \u001b[38;5;241m=\u001b[39m MCTSNode(game, target_color\u001b[38;5;241m=\u001b[39mtarget_color, flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflag) \u001b[38;5;66;03m# 创建一个MCTSNode对象，表示根节点\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m best_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMCTS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 使用MCTS算法选择最佳的子节点\u001b[39;00m\n\u001b[0;32m    111\u001b[0m game\u001b[38;5;241m.\u001b[39mset_current_win_rate(best_child\u001b[38;5;241m.\u001b[39mget_win_rate())\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_child\u001b[38;5;241m.\u001b[39mget_current_move()\n",
      "File \u001b[1;32mg:\\Project\\Celestial-Chess\\ai\\mcts.py:119\u001b[0m, in \u001b[0;36mMCTSAI.MCTS\u001b[1;34m(self, root)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitermax):\n\u001b[0;32m    118\u001b[0m     node \u001b[38;5;241m=\u001b[39m tree_policy(root)\n\u001b[1;32m--> 119\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     node\u001b[38;5;241m.\u001b[39mbackpropagate(reward)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m root\u001b[38;5;241m.\u001b[39mget_best_child(c_param\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mg:\\Project\\Celestial-Chess\\ai\\mcts.py:76\u001b[0m, in \u001b[0;36mMCTSNode.simulate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m     move \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(possible_moves)\n\u001b[0;32m     75\u001b[0m     color \u001b[38;5;241m=\u001b[39m current_simulation_state\u001b[38;5;241m.\u001b[39mget_color()\n\u001b[1;32m---> 76\u001b[0m     \u001b[43mcurrent_simulation_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_chessboard\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m winner \u001b[38;5;241m=\u001b[39m current_simulation_state\u001b[38;5;241m.\u001b[39mwho_is_winner()\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m winner \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_color:\n",
      "File \u001b[1;32mg:\\Project\\Celestial-Chess\\game\\chess_game.py:51\u001b[0m, in \u001b[0;36mChessGame.update_chessboard\u001b[1;34m(self, row, col, color)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmark_black_holes(visited)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_board[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchessboard\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_move[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep] \u001b[38;5;241m=\u001b[39m (row, col)\n",
      "File \u001b[1;32mg:\\ProgramData\\miniforge3\\envs\\chessenv\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mg:\\ProgramData\\miniforge3\\envs\\chessenv\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mg:\\ProgramData\\miniforge3\\envs\\chessenv\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mg:\\ProgramData\\miniforge3\\envs\\chessenv\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mg:\\ProgramData\\miniforge3\\envs\\chessenv\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mg:\\ProgramData\\miniforge3\\envs\\chessenv\\lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mg:\\ProgramData\\miniforge3\\envs\\chessenv\\lib\\copy.py:128\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    124\u001b[0m     d[PyStringMap] \u001b[38;5;241m=\u001b[39m PyStringMap\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m d, t\n\u001b[1;32m--> 128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeepcopy\u001b[39m(x, memo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, _nil\u001b[38;5;241m=\u001b[39m[]):\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deep copy operation on arbitrary Python objects.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    See the module's __doc__ string for more info.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m memo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_model_score_by_mcts(test_mcts_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/99 [01:58<1:36:03, 59.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chess_ai_model(06-13-19).pth : {10: 0.7, 20: 0.68, 30: 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/99 [01:58<1:36:08, 59.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chess_ai_model(06-15-17)(1506).pth : {10: 0.7, 20: 0.51, 30: 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/99 [01:50<1:29:12, 55.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chess_ai_model(06-15-17)(1471).pth : {10: 0.75, 20: 0.65, 30: 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/99 [00:51<1:24:09, 51.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chess_ai_model(06-15-17)(936).pth : {10: 0.63, 20: 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/99 [08:03<2:31:38, 96.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chess_ai_model(06-15-17)(15475).pth : {10: 0.82, 20: 0.76, 30: 0.65, 40: 0.57, 50: 0.56, 60: 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/99 [07:03<2:12:42, 84.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chess_ai_model(06-15-17)(9598).pth : {10: 0.84, 20: 0.58, 30: 0.57, 40: 0.61, 50: 0.56, 60: 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:20<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chess_ai_model(06-16-15)(1400).pth : {10: 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'models/chess_ai_model(06-13-19).pth': 20,\n",
       " 'models/chess_ai_model(06-15-17)(1506).pth': 20,\n",
       " 'models/chess_ai_model(06-15-17)(1471).pth': 20,\n",
       " 'models/chess_ai_model(06-15-17)(936).pth': 10,\n",
       " 'models/chess_ai_model(06-15-17)(15475).pth': 50,\n",
       " 'models/chess_ai_model(06-15-17)(9598).pth': 50,\n",
       " 'models/chess_ai_model(06-16-15)(1400).pth': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for path in deep_learning_dict.keys():\n",
    "    deep_learning_ai = DeepLearningAI(path)\n",
    "    score, score_dict = get_model_score_by_mcts(deep_learning_ai)\n",
    "    deep_learning_dict[path] = score\n",
    "    print(f\"{path} : {score_dict}\", end = '\\n')\n",
    "\n",
    "deep_learning_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chessenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
